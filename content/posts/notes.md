+++
title = 'notes'
date = 2024-05-31
draft = false
+++

> this contains my notes, me logging my thoughts on projects/goals/life etc as i go through them along the way. *it would be edited constantly & the latest log would always be on top.*


- 31may24

i feel so limited many a times. saw demon slayer's hashira training arc new episode: tanjiro is training & others feel like he's something different and beyond their common humans BUT this is how he felt when he started, he felt helpless and cried. its when he faced upper ranks, lost rengoku, almost died many times but survived. those scars are what make him, but its not him to complain or stop, always focused on high quality result: to defeat muzan. his insane grueling training but with a kind smile on his face is a such a powerful thing to see, it moved me.

the limitations i feel are self-inflicted, i'm on self-help for sabotage, no one from outside is even required lol. saw a 18yo waterloo guy on X building an oss replit. insane. i can push my limits up there. "skill issue" as yacine tweeted came from waterloo guys teasing for not getting into janestreet & making 400k as interns. now, that's another level of playing field but people exist there, 

i can rise to it too. constantly raising my limits is the only thing i need to do: with insane work and a smile because i'm not fighting against life, i'm living it. it should be fun.

> "surpass your limits, right here, right now. thats the only way" ---yami sukehiro.



- 24may24

been slacking last few days. so much to do and you feel small and feel there's no time? well, you're correct but its probably the most important time in human history & you're whining? you've blood flowing through you, well and alive and yet you feel you can't. yacine san said me too: "you really can". i have the humanity's finest creation machine LLM god by my side and i can just do things. i need to do enough things to understand that i can actually *just do* anything.
![24may24.yacine_said_i_can](/assets/notes/24may24.yacine_said_i_can.webp)

- 17may24

started diving deep into mlx. its new, so its clean and the implementations of `nn.Module`, c++ bindings with `mlx.core` is interesting. i did the 'hello world' of DL with training mlp on mnist. will move onto LM and then vision.

wrapped in my morning deep thought: 
![love-and-life-thought](/assets/notes/17may24.1.webp)

- 10may24

been a lot of gap but i'll try to consistently write here. i graduated, was shifting places, travelling, not a lot of work done but i'm back. my macbook's charging adapter is acting funny, so apple care folks told me to submit for 4-5 days & may potentially also format my data. like wth? lotta time spent in backing up data in usb.

now, work:
i have a list of interesting work to explore. i'm slow, like a damn tortoise. i need speed, become speed because "slowness once justifies slowness elsewhere". what i'm absolutely sure of that becoming genuinely cracked is the true path i need to take. there're a lot of talkers on X (sometimes i feel i'm them too) but raw quality of a diamond is what matters. so son, "if you gotta shine like a son, first burn like a sun". its fun, not that bad though. I CAN JUST DO THINGS & BECOME GOOD.

the work to explore includes different "arcs":
![todos-ss](/assets/notes/10may24.1.webp)

i'm excited by the fact that i can just train models on my mac with mlx, that unlocks so much. gotta try train smol million param models beyond chinchilla (since llama3), then vision & so on. also, "tokenizer is a necessary evil". karpathy also *delved* into it, so gotta do that too.

everything aside, back to home & gotta get back to my boxing training.

- 19apr24

late update but lagllama + encoder-decoder model is done.

- 03apr24

have to complete the time-series-transformers project (also, college's major project) which includes multivariate data: streamflow, rainfall, temperature etc. i've been procrastinating it on forever & my friend did his part of LSTM, i gotta ship something by end of today. i've a hf's decoder probabilistic one but damn its dataset cleaning has been tough, also i've an encoder-decoder in mind, spatio-temporal transformer's "Long transformer paper" i read much much earlier and yeah, a latest foundation lagllama model (gotta finetune).

by today gotta do the: probablistic decoder + encoder-decoder.

life is all a game of endurance, always has been. i'm thinking of getting this published in a Q1, now i've the support of a great prof, let's not waste this.